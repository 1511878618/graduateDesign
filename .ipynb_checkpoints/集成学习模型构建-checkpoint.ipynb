{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import feature as fe \n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countFeatures(data):\n",
    "    import feature \n",
    "    \"\"\"\n",
    "    input: 输入BCEs或者非BCEs的数据集 pd.DataFrame类型\n",
    "    output:输出包含AAC、DPC、CTD和AAI的 pd.DataFrame类型\n",
    "    \n",
    "    \"\"\"\n",
    "    #计算AAC\n",
    "    data['AAC']= data['Description'].apply(fe.CalculateAAComposition)\n",
    "    #计算DPC\n",
    "    data['DPC']= data['Description'].apply(fe.CalculateDipeptideComposition)\n",
    "    #计算CTD\n",
    "    data['CTD']= data['Description'].apply(fe.CalculateCTD)\n",
    "    #计算AAI\n",
    "    data['AAI']= data['Description'].apply(fe.CalculateAAIndex)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取 词分类器\n",
    "with open('tfsModel/RNNamino_acids_toknizer.json','r') as f:\n",
    "    toknizer =tf.keras.preprocessing.text.tokenizer_from_json(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applynumpyArray1D(arr,func):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    array = copy.deepcopy(arr)  \n",
    "    for i in range(array.shape[0]):\n",
    "        array[i] = func(array[i])\n",
    "    return array\n",
    "\n",
    "def normize(array):\n",
    "    \"\"\"\n",
    "    input: np.array shape = (n,) 一维向量 \n",
    "    output: 对 输入的数据进行归一化，即 (a_i - a.mean())/a.std  若全为0，则返回原array。\n",
    "    \n",
    "    \"\"\"\n",
    "    if (array == 0).all:\n",
    "        normizedarray = array\n",
    "    else:\n",
    "        normizedarray = (array-array.mean())/array.std()\n",
    "    return normizedarray\n",
    "\n",
    "def twoDArraynormize(twoDArray):\n",
    "    \"\"\"\n",
    "    input: np.array, shape = (n,m)  n为样本个数，m为特征个数，  对每一个样本的同一个特征进行归一化处理即 (m_i - m's mean)/m'std\n",
    "    output: np.array, shape = (n,m) n为样本个数，m为特征个数。 归一化后的结果 \n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(twoDArray.shape[1]):\n",
    "        array = twoDArray[:,i]\n",
    "        twoDArray[:,i] = normize(array)\n",
    "    return twoDArray\n",
    "    \n",
    "    \n",
    "\n",
    "#词向量化\n",
    "def amino_acids2numvector(sequenceArray,toknizer):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        sequence:(n,) np.array类型，多肽序列\n",
    "        toknizer: 氨基酸toknizer。    \n",
    "    output:（n,200) 数字化后的多肽序列\n",
    "    \"\"\"\n",
    "    sequenceArray = applynumpyArray1D(sequenceArray,lambda x: ' '.join(x))\n",
    "    sequenceArray = toknizer.texts_to_sequences(sequenceArray)\n",
    "    #选取最常长度为20\n",
    "    sequenceArray = tf.keras.preprocessing.sequence.pad_sequences(sequenceArray,truncating='post',padding='post',maxlen=20)\n",
    "    return sequenceArray\n",
    "\n",
    "\n",
    "#AAC Matrix\n",
    "def aminoacids2AACMatrix(array):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    tmp = copy.deepcopy(array)\n",
    "    tmp = applynumpyArray1D(tmp,fe.CalculateAAComposition)\n",
    "    AACMatrix = applynumpyArray1D(tmp,lambda x: [i for i in x.values()])#输出是（n,)的shape\n",
    "    #转化为np.array，shape为（n,20）\n",
    "    AACMatrix = np.array(AACMatrix.tolist())\n",
    "    return AACMatrix\n",
    "\n",
    "#DPC Matrix\n",
    "#DPC Matrix\n",
    "def aminoacids2DPCMatrix(array):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    tmp = copy.deepcopy(array)\n",
    "    tmp = applynumpyArray1D(tmp,fe.CalculateDipeptideComposition)\n",
    "    DPCMatrix = applynumpyArray1D(tmp,lambda x: [i for i in x.values()])#输出是（n,)的shape\n",
    "    #转化为np.array，shape为（n,20）\n",
    "    DPCMatrix = np.array(DPCMatrix.tolist())\n",
    "    return DPCMatrix\n",
    "\n",
    "#CTD Matrix\n",
    "def aminoacids2CTDMatrix(array):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    tmp = copy.deepcopy(array)\n",
    "    tmp = applynumpyArray1D(tmp,fe.CalculateCTD)\n",
    "    CTDMatrix = applynumpyArray1D(tmp,lambda x: [i for i in x.values()])#输出是（n,)的shape\n",
    "    #转化为np.array，shape为（n,20）\n",
    "    CTDMatrix = np.array(CTDMatrix.tolist())\n",
    "    return CTDMatrix\n",
    "#AAI Matrix\n",
    "def aminoacids2AAIMatrix(array):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    tmp = copy.deepcopy(array)\n",
    "    tmp = applynumpyArray1D(tmp,fe.CalculateAAIndex)\n",
    "    AAIMatrix = applynumpyArray1D(tmp,lambda x: [i for i in x.values()])#输出是（n,)的shape\n",
    "    #转化为np.array，shape为（n,20）\n",
    "    AAIMatrix = np.array(AAIMatrix.tolist())\n",
    "    return AAIMatrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generateFeaturesData(sequenceData):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        sequence:(n,) np.array类型，包含n条多肽序列的数组\n",
    "    output:[AAC,DPC,CTD,AAI,SeqVec]的一个列表\n",
    "    \"\"\"\n",
    "    data = copy.deepcopy(sequenceData)\n",
    "    AAC = aminoacids2AACMatrix(data)\n",
    "    AAC = twoDArraynormize(AAC)\n",
    "    \n",
    "    DPC = aminoacids2DPCMatrix(data)\n",
    "    DPC = twoDArraynormize(DPC)\n",
    "    \n",
    "    CTD = aminoacids2CTDMatrix(data)\n",
    "    CTD = twoDArraynormize(CTD)\n",
    "    \n",
    "    AAI = aminoacids2AAIMatrix(data)\n",
    "    AAI = twoDArraynormize(AAI)\n",
    "    \n",
    "    SeqVec = amino_acids2numvector(data,toknizer)\n",
    "    return [AAC,DPC,CTD,AAI,SeqVec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IBCE-EL的数据集\n",
    "B_positive = np.array([str(seq.seq) for seq in list(SeqIO.parse('B-positive.txt','fasta'))]).astype('object')\n",
    "B_negative = np.array([str(seq.seq) for seq in list(SeqIO.parse('B-positive.txt','fasta'))]).astype('object')\n",
    "B_positiveFeatures = generateFeaturesData(B_positive)\n",
    "B_negativeFeatures = generateFeaturesData(B_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "#牛奶过敏数据集\n",
    "milkAllergyBCEs = pd.read_csv('milk allergy linear BCEs bovine dataset.csv')['Description'].values\n",
    "milkAllergynonBCEs = pd.read_csv('milk allergy linear non-BCEs experiece confirmed.csv')['Description'].values\n",
    "milkAllergyBCEsFeatures = generateFeaturesData(milkAllergyBCEs)\n",
    "milkAllergynonBCEsFeatures = generateFeaturesData(milkAllergynonBCEs)\n",
    "milkAllergyTargets = np.concatenate([np.ones((milkAllergyBCEsFeatures[0].shape[0],)),np.zeros((milkAllergynonBCEsFeatures[0].shape[0],))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  1,  6, 17,  8, 18,  1,  7, 14, 12,  6, 11, 10,  1,  2,  2, 10,\n",
       "       16,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split( x_data, y_data, test_size=0.1)\n",
    "#MilkTrainDataset  = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(1000).batch(100)\n",
    "#MilktestDataset  = tf.data.Dataset.from_tensor_slices((x_test,y_test)).shuffle(1000).batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取模型\n",
    "AACModel = tf.keras.models.load_model('tfsModel/AACModel.h5')\n",
    "DPCModel = tf.keras.models.load_model('tfsModel/DPCModel.h5')\n",
    "CTDModel = tf.keras.models.load_model('tfsModel/CTDModel.h5')\n",
    "AAIModel = tf.keras.models.load_model('tfsModel/AAIModel.h5')\n",
    "RNNModel = tf.keras.models.load_model('tfsModel/RNNModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 836us/step - loss: 0.5351 - acc: 0.7241 - mae: 0.3655 - auc: 0.7380\n",
      "29/29 [==============================] - 0s 935us/step - loss: 0.6968 - acc: 0.8750 - mae: 0.1402 - auc: 0.9256\n",
      "29/29 [==============================] - 0s 872us/step - loss: 0.4984 - acc: 0.7953 - mae: 0.3376 - auc: 0.8397\n",
      "29/29 [==============================] - 0s 779us/step - loss: 0.5608 - acc: 0.8319 - mae: 0.2436 - auc: 0.8882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5608154535293579,\n",
       " 0.8318965435028076,\n",
       " 0.24362005293369293,\n",
       " 0.8882278203964233]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AACModel.evaluate(x=np.concatenate([milkAllergyBCEsFeatures[0],milkAllergynonBCEsFeatures[0]]),\n",
    "                 y = milkAllergyTargets,batch_size=16)\n",
    "\n",
    "DPCModel.evaluate(x=np.concatenate([milkAllergyBCEsFeatures[1],milkAllergynonBCEsFeatures[1]]),\n",
    "                 y = milkAllergyTargets,batch_size=16)\n",
    "\n",
    "CTDModel.evaluate(x=np.concatenate([milkAllergyBCEsFeatures[2],milkAllergynonBCEsFeatures[2]]),\n",
    "                 y = milkAllergyTargets,batch_size=16)\n",
    "\n",
    "AAIModel.evaluate(x=np.concatenate([milkAllergyBCEsFeatures[3],milkAllergynonBCEsFeatures[3]]),\n",
    "                 y = milkAllergyTargets,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "AACProb =AACModel.predict(x=np.concatenate([milkAllergyBCEsFeatures[2],milkAllergynonBCEsFeatures[2]]),)\n",
    "AACProb =AACModel.predict()\n",
    "CTDProb =CTDModel.predict(x=np.concatenate([milkAllergyBCEsFeatures[2],milkAllergynonBCEsFeatures[2]]),)\n",
    "AACProb =AACModel.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.923"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.concatenate([milkAllergyBCEsFeatures[2],milkAllergynonBCEsFeatures[2]]),\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
